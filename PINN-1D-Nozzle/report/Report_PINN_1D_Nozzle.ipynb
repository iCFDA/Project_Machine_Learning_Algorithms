{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Network for steady 1D C-D Nozzle Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file is a brief explanantion of the problem statement, and our approach to solve the problem.\n",
    "Note that the .ipynb Jupyter notebook code file is separately attached and itself is well commented and explained in the source file. Please refer the same for details of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create a Physics informed Neural Network or **'PINN'** in short, which can replicate the effect of **changing back pressure** of a steady 1D converging-diverging nozzle, and __accurately predict the physical state of fluid at any point through the nozzle length.__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically to train a Neural network based on the parameters to be input: Back Pressure and x (point at which output quantities are desired) and accurately predict density (rho), pressure (P), speed (u) and specific energy (E) at that point. But this would just give an ordinary deep learning network trained entirely based on the data, acting as a black box which just takes 2 inputs and produces 4 outputs. What we desire is a 'Physics Informed' neural network, meaning it abides the laws of Phyics apart from just matching ground truth output and predicted output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we incorporated Physics will follow later in the solution, for now the problem needs to be defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume a converging-diverging nozzle with cross section Area given by:\n",
    "\n",
    "\\begin{align}\n",
    "\\textbf{S}(x) &= 1 + 2.2(3 x - 1.5)^2 \\\\\n",
    "\\end{align}\n",
    "\n",
    "where **x** is the distance from left end of the nozzle, *range (0,1)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"http://www.dept.aoe.vt.edu/~devenpor/aoe3114/CD%20Nozzle%20Sim/fig1.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The governing conservative form Euler equation to solve steady 1D Nozzle problem numerically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial [S\\textbf{u}]}{\\partial t} + \\frac{\\partial [S\\textbf{F}]}{\\partial x} - \\textbf{B}\\frac{\\partial S}{\\partial x} = 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where\n",
    "\\begin{equation*}\n",
    "\\textbf{u} = \n",
    "\\begin{bmatrix}\n",
    "\\rho \\\\\n",
    "\\rho u \\\\\n",
    "\\rho E\n",
    "\\end{bmatrix},\n",
    "\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\n",
    "\\textbf{F} = \n",
    "\\begin{bmatrix}\n",
    "\\rho u \\\\\n",
    "\\rho u^2 + P \\\\\n",
    "(\\rho E + P)u\n",
    "\\end{bmatrix}\n",
    "\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\n",
    "\\textbf{B} = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "P \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve numerically and generate data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above equation is used in a higher order scheme of 100 data point 1D mesh in order to generate data with the use of appropriate boundary conditions. A loop is written in the same file, to input differnet back pressures and get the values of Pressure, desity, speed and energy of the fluid at each point in the mesh. This data is stored in a .txt readable file to be used as data set for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a neural network trained of the above data set, and also which abides the Laws of Physics as provided by the Euler equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the solution is simple, create a basic deep learning framework and test your network. Note that we have to divide the dataset into training set and test set randomly first and then perform the training on the training data set. For plotting the reults and esting the performance alone would the test data set be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part although demands Physics to be taught to the network. We want the network to train, while following the governing equations at each iteration step. This can be implemented by minimizing the residuals generated when the steady state ezpressions are evaluated from the predicted output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady equation written in terms of fundamental quantitites:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial (\\rho u S)}{\\partial x} = 0 \\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial ((\\rho u^2 + P)S)}{\\partial x} - P\\frac{\\partial S}{\\partial x} = 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial ((\\rho E + P)uS)}{\\partial x} = 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since the training set itself is dicretized and plus our network has inaccuracies, there will always be a residual when we actually put the values of output in the above equations, or in other words, it can never be absolute 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals and new loss function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial (\\rho u S)}{\\partial x} = e1 \\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial ((\\rho u^2 + P)S)}{\\partial x} - P\\frac{\\partial S}{\\partial x} = e2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial ((\\rho E + P)uS)}{\\partial x} = e3\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to reducing the Mean Squared Error (MSE) of the ground truth outputs and predicted outputs of the 4 parameter variables, we try to minimize the squared error residuals generated by the steady state governing equations.\n",
    "\n",
    "The __loss__ will now be calculated with additional terms: **e<sup>2</sup>** + .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e.\n",
    "\\begin{equation*}\n",
    "\\textbf{loss} = MSE + e_{1}^{2} + e_{2}^{2} + e_{3}^{2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally and hypothetically, if the loss goes to zero, it means that all the square terms are zero individually. This means that not only is the predicted output exaclty matching the corresponding ground truth but also for each data point of the dataset, the steady state governing equations are satisfied. This is the ideal Physics informed Neural network. \n",
    "\n",
    "\n",
    "But it cannot happen due to the reason mentioned before, and the network will converge loss to a very small value impying being trained and 'Physics informed'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But how do we differentiate the network outputs with respect to x?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the previous section, to calculate residuals, we need the partial x derivatives of outputs or some combination of outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a special condition of back propagation, which is basically chain rule to find exact derivatives of output variables with respect to all weights.\n",
    "\n",
    "This method is also called Automatic Differential (AutoDiff) and forms the very backbone of training deep learning networks. Backprop is the most common application of AutoDiff.\n",
    "\n",
    "**More on Backprop in another documentation file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.gradients(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow provides an inbuilt default function to calculate gradients or to perform AutoDiff in other words. The only parameters it needs is the numerator variable (a) to be differnetiated partially and the variable (or weight) to differentiate a with respect to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\textbf{tf.gradients(a,b)} = \\frac{\\partial a}{\\partial b}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is literally that simple to find the gradients using AutoDiff. For example, in our case, to find continuity equation residual, we want 'a' should be quantities __mass flow rate__ and 'b' to be __x__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "\\begin{equation*}\n",
    "e_{1} = \\frac{\\partial (\\rho u S)}{\\partial x} = tf.gradients(\\rho uS, x)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we find the residuals and add the squared errors into the loss function expression for the optimizer to minimize."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
